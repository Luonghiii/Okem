import requests
import os
import json

# ====== Cáº¤U HÃŒNH ======
HF_API_KEY = os.getenv("HF_API_KEY") or "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"

MODELS = {
    "1": "mistralai/Mistral-7B-Instruct-v0.3",
    "2": "microsoft/Phi-3-mini-4k-instruct",
    "3": "Qwen/Qwen2.5-7B-Instruct"
}

current_model_key = "1"

def chat(prompt):
    model_id = MODELS[current_model_key]
    url = f"https://router.huggingface.co/hf-inference/models/{model_id}"

    headers = {
        "Authorization": f"Bearer {HF_API_KEY}",
        "Content-Type": "application/json"
    }

    payload = {
        "inputs": prompt
    }

    res = requests.post(url, headers=headers, json=payload, timeout=60)
    return res.json()

def show_models():
    print("\nğŸ“¦ Danh sÃ¡ch model:")
    for k, v in MODELS.items():
        active = "âœ…" if k == current_model_key else "  "
        print(f"{active} {k}. {v}")
    print("GÃµ: /model <sá»‘> Ä‘á»ƒ Ä‘á»•i model")
    print("GÃµ: /exit Ä‘á»ƒ thoÃ¡t\n")

print("ğŸ¤— Hugging Face Chat (FREE)")
print("GÃµ /model Ä‘á»ƒ Ä‘á»•i model | /exit Ä‘á»ƒ thoÃ¡t")
show_models()

while True:
    user_input = input("ğŸ‘¤ Báº¡n: ").strip()

    if user_input.lower() in ["/exit", "exit", "quit"]:
        print("ğŸ‘‹ Táº¡m biá»‡t!")
        break

    if user_input.startswith("/model"):
        _, *args = user_input.split()
        if args and args[0] in MODELS:
            current_model_key = args[0]
            print(f"âœ… ÄÃ£ Ä‘á»•i sang model: {MODELS[current_model_key]}")
        else:
            print("âŒ Model khÃ´ng há»£p lá»‡")
        show_models()
        continue

    try:
        result = chat(user_input)

        if isinstance(result, list) and "generated_text" in result[0]:
            print("ğŸ¤– AI:", result[0]["generated_text"])
        else:
            print("âš ï¸ Pháº£n há»“i láº¡:")
            print(json.dumps(result, indent=2, ensure_ascii=False))

    except Exception as e:
        print("âŒ Lá»—i:", str(e))
