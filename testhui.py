from huggingface_hub import InferenceClient
import os

# ================== Cáº¤U HÃŒNH ==================
# KhuyÃªn dÃ¹ng biáº¿n mÃ´i trÆ°á»ng:
# export HF_API_KEY="hf_xxx"
HF_API_KEY = os.getenv("HF_API_KEY")

MODEL_ID = "mistralai/Mistral-7B-Instruct-v0.3"
# ==============================================

if not HF_API_KEY:
    print("âŒ ChÆ°a cÃ³ HF_API_KEY (export HF_API_KEY trÆ°á»›c)")
    exit(1)

client = InferenceClient(
    model=MODEL_ID,
    token=HF_API_KEY
)

print("ğŸ¤— HF Chat (InferenceClient â€“ HF má»›i)")
print("GÃµ 'exit' Ä‘á»ƒ thoÃ¡t")
print("-" * 40)

while True:
    user = input("ğŸ‘¤ Báº¡n: ").strip()
    if user.lower() in ["exit", "quit"]:
        print("ğŸ‘‹ Táº¡m biá»‡t!")
        break

    try:
        reply = client.text_generation(
            user,
            max_new_tokens=256,
            temperature=0.7,
            top_p=0.9,
        )
        print("ğŸ¤– AI:", reply)

    except Exception as e:
        print("âŒ Lá»—i:", str(e))
